---
title: 'About'
permalink: /about/index.html
---

The Fluid Corpus Manipulation project (FluCoMa) instigates new musical ways of exploiting ever-growing banks of sound and gestures within the digital composition process, by bringing breakthroughs of signal decomposition DSP and machine learning to the toolset of techno-fluent computer composers, creative coders and digital artists.

These potent algorithms are currently partially available in closed bespoke software, or in laboratories, but not at a suitable level of modularity within the main coding environments used by the creative researchers, namely [Max](https://cycling74.com/products/max/), [Pd](http://puredata.info/) and [SuperCollider](http://supercollider.github.io/), to allow groundbreaking sonic research into a rich unexploited area: the manipulation of large sound corpora. Indeed, with access to, genesis of, and storage of large sound banks now commonplace, novel ways of abstracting and manipulating them are needed to mine their inherent potential.

FluCoMa proposes to tackle this issue by empowering techno-fluent aesthetic researchers with a toolset for signal decomposition, and one for machine learning, as well as support material, in order to experiment with new sound and gesture design untapped in large corpora from within their high-level creative coding workflow. Three degrees of manipulations are set to be explored: (1) expressive browsing and descriptor-based taxonomy, (2) remixing, component replacement, and hybridisation by concatenation, and (3) pattern recognition at component level, with interpolating and variation-making potential. These novel manipulations will yield new sounds, new musical ideas, and new approaches to large corpora.

As with previous [HISS](http://www.thehiss.org/) projects, FluCoMa will deliver its findings open source, in the form of software (standalone and extensions) with extensive documentation and examples, as well as the underlying libraries in C++. Moreover, musical works commissioned to challenge these new methodologies will be released, through concerts and plenaries on surrounding subjects, and documented in academic papers. A users forum will also be at the centre of this emerging research community.

FluCoMa is based within the [Department of Music and Music Technology](https://research.hud.ac.uk/music/), with its [Centre for Research in New Music](http://www.cerenem.org/), on the Queensgate Campus of the [University of Huddersfield](http://www.hud.ac.uk/). This project has received funding from the [European Union's Horizon 2020 research and innovation programme](https://erc.europa.eu/) under grant agreement No 725899.

### <a name="cite"></a>How To Cite

Please cite us if you use the [software](/download) and/or the [learning resources](https://learn.flucoma.org). 

When used in an artistic context, a simple line thanking us is appreciated. A tag on social media ([Facebook](https://www.facebook.com/flucoma), [Twitter](https://twitter.com/flucoma), [Instagram](https://www.instagram.com/flucoma/)) is also welcome.

In more academic settings, for any use of the toolkit, we would appreciate citations to the following reference:

*Tremblay, P.A., Green, O., Roma, G., Bradbury, J., Moore, T., Hart, J., & Harker, A. (2022)* **The Fluid Corpus Manipulation Toolbox (v.1).** Zenodo. [doi: /10.5281/zenodo.6834643](https://doi.org/10.5281/zenodo.6834643)

If you want to cite the design considerations and code infrastructure, you may also want to consider the following paper:

*Tremblay, P.A., Roma, G., & Green, O. (2022)* **Enabling Programmatic Data Mining as Musicking: The Fluid Corpus Manipulation Toolkit.** Computer Music Journal 2022; 45 (2): 9â€“23. [doi: /10.1162/comj_a_00600](https://doi.org/10.1162/comj_a_00600)

For a complete list of our publications, see the [publication page](/publications).